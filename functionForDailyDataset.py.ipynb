{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cfa9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "573a9ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(0,24):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(1,16):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_29t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    if(len(data_frames)!=0):\n",
    "        df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "        columns=['bike_id']\n",
    "        for i in files:\n",
    "            columns.append('lat_%s' %i)\n",
    "            columns.append('lon_%s' %i)\n",
    "            columns.append('range_%s' %i)\n",
    "        #print(columns)\n",
    "        #add created colunm names\n",
    "        df_merged.columns = columns\n",
    "        #save file\n",
    "        df_merged.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}hour_part1.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7050175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(9,24):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(16,31):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_29t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}hour_part2.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01436888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(9,24):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(31,46):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_29t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}hour_part3.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "609ebd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(9,24):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(46,60):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_29t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}hour_part4.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "978bfb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for minute in range(9,24):\n",
    "    if((minute+1)!=24):\n",
    "        with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_29t{}_0.json'.format(minute+1),'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "    else:\n",
    "        with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_30t0_0.json','r') as f:\n",
    "            data = json.loads(f.read())\n",
    "    df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "    df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "    df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "    df=pd.DataFrame(df_normalized_escooter)\n",
    "    df.columns = ['bike_id', 'lat_60', 'lon_60', 'range_60']\n",
    "    part4=pd.read_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}hour_part4.csv'.format(minute))\n",
    "    df_4=part4.merge(df, how='outer', on='bike_id')\n",
    "    df_4.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}hour_part4.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f74a5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateSetPerHour(day):\n",
    "    for hour in range(0,24):\n",
    "#first part of the data\n",
    "        data_frames1 = []\n",
    "        files1=[]\n",
    "        for file_id in range(1,16):\n",
    "            try:\n",
    "                with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t{}_{}.json'.format(day,hour,file_id),'r') as f:\n",
    "                    data = json.loads(f.read())\n",
    "                df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "                df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "                df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "                df=pd.DataFrame(df_normalized_escooter)\n",
    "                data_frames1.append(df)\n",
    "                files1.append(file_id)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        if(len(data_frames1)!=0):\n",
    "            df_merged1 = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                                   how='outer'), data_frames1)\n",
    "            #create dynamic column names\n",
    "            columns1=['bike_id']\n",
    "            for i in files1:\n",
    "                columns1.append('lat_%s' %i)\n",
    "                columns1.append('lon_%s' %i)\n",
    "                columns1.append('range_%s' %i)\n",
    "            #print(columns)\n",
    "            #add created colunm names\n",
    "            df_merged1.columns = columns1\n",
    "            #save file\n",
    "            df_merged1.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}_{}hour_part1.csv'.format(day,hour), index=False)\n",
    "#second part of the data\n",
    "        data_frames2= []\n",
    "        files2=[]\n",
    "        for file_id in range(16,31):\n",
    "            try:\n",
    "                with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t{}_{}.json'.format(day,hour,file_id),'r') as f:\n",
    "                    data = json.loads(f.read())\n",
    "                df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "                df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "                df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "                df=pd.DataFrame(df_normalized_escooter)\n",
    "                data_frames2.append(df)\n",
    "                files2.append(file_id)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        if(len(data_frames2)!=0):\n",
    "            df_merged2 = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                                   how='outer'), data_frames2)\n",
    "            #create dynamic column names\n",
    "            columns2=['bike_id']\n",
    "            for i in files2:\n",
    "                columns2.append('lat_%s' %i)\n",
    "                columns2.append('lon_%s' %i)\n",
    "                columns2.append('range_%s' %i)\n",
    "            #add created colunm names\n",
    "            df_merged2.columns = columns2\n",
    "            #save file\n",
    "            df_merged2.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}_{}hour_part2.csv'.format(day,hour), index=False)\n",
    "#Third part of the dataset\n",
    "        data_frames3= []\n",
    "        files3=[]\n",
    "        for file_id in range(31,46):\n",
    "            try:\n",
    "                with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t{}_{}.json'.format(day,hour,file_id),'r') as f:\n",
    "                    data = json.loads(f.read())\n",
    "                df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "                df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "                df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "                df=pd.DataFrame(df_normalized_escooter)\n",
    "                data_frames3.append(df)\n",
    "                files3.append(file_id)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        if(len(data_frames3)!=0):\n",
    "            df_merged3 = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                                   how='outer'), data_frames3)\n",
    "            #create dynamic column names\n",
    "            columns3=['bike_id']\n",
    "            for i in files3:\n",
    "                columns3.append('lat_%s' %i)\n",
    "                columns3.append('lon_%s' %i)\n",
    "                columns3.append('range_%s' %i)\n",
    "            #add created colunm names\n",
    "            df_merged3.columns = columns3\n",
    "            #save file\n",
    "            df_merged3.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}_{}hour_part3.csv'.format(day,hour), index=False)\n",
    "#fourth part of the dataset\n",
    "        data_frames4= []\n",
    "        files4=[]\n",
    "        for file_id in range(46,60):\n",
    "            try:\n",
    "                with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t{}_{}.json'.format(day,hour,file_id),'r') as f:\n",
    "                    data = json.loads(f.read())\n",
    "                df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "                df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "                df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "                df=pd.DataFrame(df_normalized_escooter)\n",
    "                data_frames4.append(df)\n",
    "                files4.append(file_id)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        if(len(data_frames4)!=0):\n",
    "            df_merged4 = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                                   how='outer'), data_frames4)\n",
    "            #create dynamic column names\n",
    "            columns4=['bike_id']\n",
    "            for i in files4:\n",
    "                columns4.append('lat_%s' %i)\n",
    "                columns4.append('lon_%s' %i)\n",
    "                columns4.append('range_%s' %i)\n",
    "            #add created colunm names\n",
    "            df_merged4.columns = columns4\n",
    "            #save file\n",
    "            df_merged4.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}_{}hour_part4.csv'.format(day,hour), index=False)\n",
    "#new minute (next_hour:00) data merge to fourth part of the dataset\n",
    "            try:\n",
    "                if((hour+1)!=24):\n",
    "                    with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t{}_0.json'.format(day,(hour+1)),'r') as f:\n",
    "                        data = json.loads(f.read())\n",
    "                else:\n",
    "                    with open(r'C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t0_0.json'.format(day+1),'r') as f:\n",
    "                        data = json.loads(f.read())\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            df.columns = ['bike_id', 'lat_60', 'lon_60', 'range_60']\n",
    "            part4=pd.read_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}_{}hour_part4.csv'.format(day,hour))\n",
    "            df_4=part4.merge(df, how='outer', on='bike_id')\n",
    "            df_4.to_csv(r'C:\\Melbourne_Escooter\\RealDataset\\Results\\July\\{}_{}hour_part4.csv'.format(day,hour), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41ae742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateSetPerHourTEST(day):\n",
    "    for minute in range(9,24):\n",
    "        data_frames1 = []\n",
    "        files1=[]\n",
    "        for file_id in range(1,16):\n",
    "            print('C:\\Melbourne_Escooter\\RealDataset\\July\\7_{}t{}_{}.json'.format(day,minute,file_id))\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a60f1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_a', 'current_range_meters_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "dateSetPerHour(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea222de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
