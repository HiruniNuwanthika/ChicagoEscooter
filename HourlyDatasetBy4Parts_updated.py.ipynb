{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64af6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f4873d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 27, 28]\n"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "files=[]\n",
    "for i in range(25,29):\n",
    "    try:\n",
    "        with open(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_29t18_{}.json'.format(i),'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "        df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "        df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "        df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "        df=pd.DataFrame(df_normalized_escooter)\n",
    "        data_frames.append(df)\n",
    "        files.append(i)\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                            how='outer'), data_frames)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d0569af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bike_id', 'lat_25', 'lon_25', 'range_25', 'lat_27', 'lon_27', 'range_27', 'lat_28', 'lon_28', 'range_28']\n"
     ]
    }
   ],
   "source": [
    "files\n",
    "columns=['bike_id']\n",
    "for i in files:\n",
    "    #print (i)\n",
    "    columns.append('lat_%s' %i)\n",
    "    columns.append('lon_%s' %i)\n",
    "    columns.append('range_%s' %i)\n",
    "#columns.append(files)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71b8140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a375cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\NEW7_29t18_25to7_29t18_29OUTERDynamicColumns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536684eb",
   "metadata": {},
   "source": [
    "# All 4 in 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e0b77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a43912e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'current_range_meters_a', 'lon_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(15,17):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(1,16):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\7_31t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\Results\\{}hour_part1.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef70e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'current_range_meters_a', 'lon_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(15,17):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(16,31):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\7_31t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\Results\\{}hour_part2.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6beb9a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'current_range_meters_a', 'lon_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(15,17):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(31,46):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\7_31t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\Results\\{}hour_part3.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db407317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'current_range_meters_a', 'lon_a', 'lat_a'} in the result is deprecated and will raise a MergeError in a future version.\n"
     ]
    }
   ],
   "source": [
    "for minute in range(15,17):\n",
    "    data_frames = []\n",
    "    files=[]\n",
    "    for file_id in range(46,60):\n",
    "        try:\n",
    "            with open(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\7_31t{}_{}.json'.format(minute,file_id),'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "            df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "            df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "            df=pd.DataFrame(df_normalized_escooter)\n",
    "            data_frames.append(df)\n",
    "            files.append(file_id)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['bike_id'],suffixes=('_a', '_b'),\n",
    "                                           how='outer'), data_frames)\n",
    "    #create dynamic column names\n",
    "    columns=['bike_id']\n",
    "    for i in files:\n",
    "        columns.append('lat_%s' %i)\n",
    "        columns.append('lon_%s' %i)\n",
    "        columns.append('range_%s' %i)\n",
    "    #print(columns)\n",
    "    #add created colunm names\n",
    "    df_merged.columns = columns\n",
    "    #save file\n",
    "    df_merged.to_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\Results\\{}hour_part4.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59e5c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for minute in range(15,17):\n",
    "    with open(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\7_31t{}_0.json'.format(minute+1),'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    df_normalized=pd.json_normalize(data, ['data', 'bikes'])\n",
    "    df_normalized_escooter=df_normalized[df_normalized['vehicle_type']=='scooter']\n",
    "    df_normalized_escooter.drop(['is_reserved', 'is_disabled','vehicle_type_id','pricing_plan_id','last_reported','vehicle_type'], axis=1, inplace=True)\n",
    "    df=pd.DataFrame(df_normalized_escooter)\n",
    "    df.columns = ['bike_id', 'lat_60', 'lon_60', 'range_60']\n",
    "    part4=pd.read_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\Results\\{}hour_part4.csv'.format(minute))\n",
    "    df_4=part4.merge(df, how='outer', on='bike_id')\n",
    "    df_4.to_csv(r'C:\\Melbourne_Escooter\\Lime\\Scheduled_downloads\\Test\\7_31_16hour\\Results\\{}hour_part4.csv'.format(minute), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d7a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8d71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
